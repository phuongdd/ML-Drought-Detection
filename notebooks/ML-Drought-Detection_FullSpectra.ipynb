{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML-Drought-Detection.ipynb","provenance":[{"file_id":"15hY2p0_n-8ULOjHULL1BOPDHDH1kZcGA","timestamp":1590127564517}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dh-q7Wo_lam7","executionInfo":{"status":"ok","timestamp":1604122964796,"user_tz":240,"elapsed":10204,"user":{"displayName":"Dao Duc-Phuong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhP2QqqIZvXO7ZRkf-V0KIa5W43H7VgeLdgjfWScA=s64","userId":"16179160677381958228"}},"outputId":"634abca2-03c6-4058-f8eb-1913430eef21","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install statannot\n","!pip install spectral\n","\n","import io\n","import os\n","import scipy\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn import metrics\n","from sklearn import datasets\n","from sklearn import svm\n","from sklearn.decomposition import PCA\n","from sklearn import preprocessing\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","from sklearn.metrics import cohen_kappa_score\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation, Dropout\n","from keras.layers import Input\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from google.colab import files\n","import seaborn as sns\n","from sklearn.neural_network._multilayer_perceptron import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from osgeo import gdal\n","from skimage import exposure\n","from sklearn import metrics\n","from matplotlib import colors\n","from spectral import*\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting statannot\n","  Downloading https://files.pythonhosted.org/packages/0f/3a/e579d7e3b855586e468375251ec093142d67c5f8ccd76482492f2a474862/statannot-0.2.3-py3-none-any.whl\n","Installing collected packages: statannot\n","Successfully installed statannot-0.2.3\n","Collecting spectral\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/06/6a89035cde4eac3ed94e1888f850af653386e8ee827edc72ffc8e445bcb7/spectral-0.22.1-py3-none-any.whl (212kB)\n","\u001b[K     |████████████████████████████████| 215kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spectral) (1.18.5)\n","Installing collected packages: spectral\n","Successfully installed spectral-0.22.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ohdjocvb4S5i"},"source":["# Define functions\n","# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n","def encode_text_index(df, name):\n","    le = preprocessing.LabelEncoder()\n","    df[name] = le.fit_transform(df[name])\n","    return le.classes_\n","\n","#-------------------------------------------------------------------------------\n","# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n","def to_xy(df, target):\n","    result = []\n","    for x in df.columns:\n","        if x != target:\n","            result.append(x)\n","\n","    # find out the type of the target column.  Is it really this hard? :(\n","    target_type = df[target].dtypes\n","    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n","\n","    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n","    if target_type in (np.int64, np.int32):\n","        # Classification\n","        dummies = pd.get_dummies(df[target])\n","        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n","    else:\n","        # Regression\n","        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n","\n","\n","#-------------------------------------------------------------------------------\n","# Plot confusion matrix for classification result\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Greys):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    #if not title:\n","    #    if normalize:\n","    #        title = 'Normalized confusion matrix'\n","    #    else:\n","    #        title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    # Only use the labels that appear in the data\n","    classes = classes[unique_labels(y_true, y_pred)]\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    fig, ax = plt.subplots(figsize=(5.5, 4.9), frameon=True)\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    cbar = ax.figure.colorbar(im, ax=ax)\n","    cbar.ax.tick_params(labelsize=13)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\",\n","             rotation_mode=\"anchor\", fontsize=12)\n","    \n","    plt.setp(ax.set_xlabel('Predicted label', fontsize=18))\n","\n","    plt.setp(ax.get_yticklabels(), rotation=90, ha=\"center\",\n","             rotation_mode=\"anchor\", fontsize=12)\n","    \n","    plt.setp(ax.set_ylabel('True label', fontsize=18))\n","    \n","    plt.setp(ax.set_title(title, fontsize=18))\n","\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt), size=13,\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax\n","\n","#-------------------------------------------------------------------------------\n","# Export classification results to GeoTIFF\n","from osgeo import gdal,osr\n","import numpy as np\n","\n","def save_raster(path, img, prj, geotran, format='GTiff', dtype = gdal.GDT_Float32):\n","    rows, cols = img.shape\n","    # Initialize driver & create file\n","    driver = gdal.GetDriverByName(format)\n","    dataset_out = driver.Create(path, cols, rows, 1, dtype)\n","    dataset_out.SetGeoTransform(geotran)\n","    dataset_out.SetProjection(prj)\n","    # Write file to disk\n","    dataset_out.GetRasterBand(1).WriteArray(img.real)\n","    dataset_out.FlushCache()\n","    dataset_out=None\n","\n","#-------------------------------------------------------------------------------\n","# Define the derivative calculation function\n","def derivative(f, x, method='central', interval=1):\n","    '''Compute the difference formula for f'(x) with step size interval.\n","    Parameters:\n","    -----------\n","    f: Function\n","       Vectorized function of one variable\n","       \n","    x: Compute derivative at wavelength x\n","       method: string - 'forward', 'backward' or 'central'\n","    \n","    interval: Step size in difference formula\n","    '''\n","    \n","    if method == 'central':\n","        return (f(x + interval) - f(x - interval))/(2*interval)\n","    elif method == 'forward':\n","        return (f(x + interval) - f(x))/interval\n","    elif method == 'backward':\n","        return (f(x) - f(x - interval))/interval\n","    else:\n","        raise ValueError(\"Method must be 'central', 'forward', or 'backward'.\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bYgWokA_w9uv"},"source":["# Code to read csv file into Colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1E0Dy12CLKIv"},"source":["# Read reflectance data for derivative calculationplt.style.use('seaborn-dark')\n","import time\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","#plt.style.use('classic')\n","plt.style.use('seaborn-ticks')\n","\n","start_time = time.process_time()\n","\n","# Preprocess the data\n","ref_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/2019_Stress_T0_Deriv_24.csv')\n","ref_data_ori = ref_data\n","status = encode_text_index(ref_data, \"Status\")\n","x_ml = ref_data.drop(['Sample', 'Status'], axis=1)\n","y_ml = ref_data['Status']\n","wavelength = np.arange(440,802,2)\n","\n","# Scale the data and split the training and test samples\n","x_ml_tran = x_ml.T\n","x_ml_tran_scaled = MinMaxScaler().fit_transform(x_ml_tran)\n","x_ml_scaled = x_ml_tran_scaled.T\n","x_ml_train, x_ml_test, y_ml_train, y_ml_test = train_test_split(x_ml_scaled, y_ml, test_size = 0.25, random_state = 42, stratify = y_ml)\n","\n","# Plot the spectral curves\n","main_font = 22\n","Sub_font = 18\n","\n","# Calculate the mean spectral curves\n","ref_mean = ref_data.groupby(\"Sample\").mean()\n","wavelength = np.arange(440,800,2)\n","\n","# Plot the mean spectra\n","plt_ref_mean = (ref_mean.iloc[0:10, 1:181].values).transpose()\n","plt_ref_mean = pd.DataFrame(plt_ref_mean, index=wavelength)\n","plt_ref_mean.plot(figsize=(8, 7), color=sns.set_palette(\"husl\", 10))\n","plt.title(\"Mean Spectral Derivative\", fontsize=main_font)\n","plt.xlabel('Wavelength (nm)', fontsize=main_font)\n","plt.ylabel('Spectral Derivative', fontsize=main_font)\n","plt.grid(color='grey', linestyle='dotted', linewidth=0.55)\n","plt.tick_params(direction = 'in', color='black')\n","plt.xticks(fontsize=Sub_font)\n","plt.xlim(430, 810)\n","plt.ylim(0, 0.4)\n","plt.yticks(fontsize=Sub_font, rotation=90)\n","plt.legend(loc='upper left', frameon=False, fontsize = Sub_font,\n","           labels = ['Day 00', 'Day 03','Day 06',\n","                     'Day 09', 'Day 12', 'Day 15',\n","                     'Day 18', 'Day 21', 'Day 24',\n","                     ],\n","           ncol=2)\n","plt.savefig('/content/gdrive/My Drive/Mean_Spectral.png', dpi=300)\n","end_time = time.process_time()\n","elapsed_time = (end_time - start_time)\n","print(\"Processing time:\", round(elapsed_time,3), \"Secs\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsYPEp3lzcMh"},"source":["# Multilayer perceptron deep (MLP) neural network classification for full images\n","#from skopt import BayesSearchCV\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.externals import joblib\n","from google.colab import drive\n","from sklearn.metrics import accuracy_score\n","import pickle\n","plt.style.use('seaborn-dark')\n","\n","start_time = time.time()\n","\n","# Setup parameters for MLP model tuning\n","mlp_parameters = {\n","    'hidden_layer_sizes': [(300,300), (300,50), (200,200), (100,100), (50,50)],\n","    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n","    'solver': ['lbfgs', 'sgd', 'adam'],\n","    'alpha': [0.00001, 0.0001, 0.001],\n","    'learning_rate': ['constant','adaptive', 'invscaling'],\n","    #'batch_size': [200, 300, 400, 500, 600, 700],\n","    #'n_iter_no_change': [30]\n","}\n","\n","mlp_grid = RandomizedSearchCV(estimator = MLPClassifier(max_iter=1000),\n","                              param_distributions=mlp_parameters, n_iter=20, cv = 10, verbose = 1, n_jobs=-1)\n","\n","mlp_grid.fit(x_ml_train, y_ml_train)\n","\n","# Print the tuning result and get the best parameters\n","print(\"The best parameters are %s with a score of %0.3f\"\n","      % (mlp_grid.best_params_, mlp_grid.best_score_))\n","\n","print(\"The best MLP model:\")\n","print(mlp_grid.best_estimator_)\n","\n","# Print the trainng results\n","mlp_means = mlp_grid.cv_results_['mean_test_score']\n","mlp_stds = mlp_grid.cv_results_['std_test_score']\n","for mean, std, params in zip(mlp_means, mlp_stds, mlp_grid.cv_results_['params']):\n","    print(\"(+%0.3f/-%0.03f) for %r\"% (mean, std * 2, params))\n","\n","#Plot the training result graph\n","plt.plot(mlp_grid.cv_results_['mean_test_score'])\n","plt.title('Model train vs. Validation loss')\n","plt.xlabel('epochs')\n","plt.ylabel('Mean square error')\n","plt.legend(['Train MSE', 'validation MSE'], loc='upper left')\n","plt.show()\n","\n","# Save the trained MLP model as a pickle file\n","drive.mount('/content/gdrive')\n","path = F\"/content/gdrive/My Drive/mlp_spectralderiv_T0_24.pkl\" \n","joblib.dump(mlp_grid, open(path, 'wb'))\n","\n","# Calculate training time\n","end_time = time.time()\n","elapsed_time = (end_time - start_time)\n","print(\"Processing time:\", round(elapsed_time,3), \"Secs\")\n","\n","\n","#-------------------------------------------------------------------------\n","# Load the model and perform MLP classification\n","mlp_classifier =  joblib.load(open(path, 'rb'))\n","\n","y_ml_pred = mlp_classifier.predict(x_ml_test)\n","\n","kappa_mlp = cohen_kappa_score(y_ml_test, y_ml_pred)\n","Overall_acc = accuracy_score(y_ml_test, y_ml_pred)\n","print('Overall Accuracy:', round(Overall_acc*100, 3))\n","print('kapa Cofficient:', round(kappa_mlp,3))\n","\n","# Plot confusion matrix\n","np.set_printoptions(precision=2)\n","\n","#Plot normalized confusion matrix\n","plot_confusion_matrix(y_ml_test, y_ml_pred, classes=status, normalize=True,\n","                      title='Normalized matrix - DNN-Deriv')\n","\n","plt.savefig(\"/content/gdrive/My Drive/mlp_spectralDeriv_matrix_T0_24.png\", dpi=300)\n","plt.show()\n","\n","# Save runtime and accuracy to CSV\n","with open('/content/gdrive/My Drive/mlp_spectralderiv_accuracy_' + 'T0' + '_24.txt', 'a', newline='') as txtfile:\n","  #row_write = csv.writer(csvfile, delimiter=' ')\n","  txtfile.write('Runtime: ' + str(round(elapsed_time, 0)) + '\\n')\n","  txtfile.write('Overall Accuracy: ' + str(round(Overall_acc*100, 3)) + '\\n')\n","  txtfile.write('Kappa Coefficient: ' + str(round(kappa_mlp, 3)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a54zQt2Q81MF","executionInfo":{"status":"ok","timestamp":1593227783553,"user_tz":240,"elapsed":8788,"user":{"displayName":"Dao Duc-Phuong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhP2QqqIZvXO7ZRkf-V0KIa5W43H7VgeLdgjfWScA=s64","userId":"16179160677381958228"}},"outputId":"5bdd60a1-a19c-44c8-b433-9e8856d40219","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Read origial raster dataset and stack image bands\n","from google.colab import drive\n","treat_day = 'D-24'\n","drive.mount('/content/gdrive')\n","img_ori_name = \"/content/gdrive/My Drive/T01_20190718_Ref_Sm_Res_Sub_440-800_segmentation.tif\"\n","\n","raster_dataset = gdal.Open(img_ori_name, gdal.GA_ReadOnly)\n","geo_transform = raster_dataset.GetGeoTransform()\n","proj = raster_dataset.GetProjectionRef()\n","n_bands = raster_dataset.RasterCount\n","\n","hsi_img = np.moveaxis(raster_dataset.ReadAsArray()[:251], 0, -1)\n","\n","#hsi_img = exposure.rescale_intensity(bands_data, out_range=(0,1))\n","plt.style.use('seaborn-ticks')\n","\n","# Display RGB image\n","# Produce mask\n","vmin = 0.15\n","vmax = 0.4\n","rgb_img = np.dstack([hsi_img[:, :, 180], hsi_img[:, :, 120], hsi_img[:, :, 55]])\n","#rgb_img = np.dstack([hsi_img[:, :, 120], hsi_img[:, :, 55], hsi_img[:, :, 5]])\n","\n","plt.figure(figsize=(6.5, 6))\n","rgb_img = exposure.rescale_intensity(rgb_img, out_range=(0,1))\n","rgb_img[(hsi_img[:, :, 180] <= vmin)] = 1e+20\n","plt.title(treat_day, fontsize=18)\n","plt.imshow(rgb_img, alpha=1)\n","plt.xticks(ticks=[], labels=None)\n","plt.yticks(ticks=[], labels=None)\n","plt.grid(b=None)\n","savefile = '/content/gdrive/My Drive/T0_rgb_img_' + treat_day\n","plt.savefig(savefile + '.png', dpi=150)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wxtL6N9U5r8g"},"source":["# Perform image classification\n","from sklearn.metrics import accuracy_score\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.externals import joblib\n","from google.colab import drive\n","from sklearn import svm\n","from pylab import *\n","import pickle\n","import gdal\n","import os\n","\n","# Load the pickled model\n","plt.style.use('seaborn-ticks')\n","drive.mount('/content/gdrive')\n","\n","day_list = ['D-00', 'D-03', 'D-06', 'D-09', 'D-12', 'D-15', 'D-18', 'D-21', 'D-24']\n","date_list = ['20190617', '20190620', '20190623', '20190626', '20190630', '20190704', '20190708', '20190712', '20190718']\n","mask_list = [0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.2, 0.15]\n","for treat_day, treat_date, mask_val in zip(day_list, date_list, mask_list):\n","  img_ori_name = '/content/gdrive/My Drive/T01_' + treat_date + '_Ref_Sm_Res_Sub_440-800_segmentation.tif'\n","\n","  raster_dataset = gdal.Open(img_ori_name, gdal.GA_ReadOnly)\n","  geo_transform = raster_dataset.GetGeoTransform()\n","  proj = raster_dataset.GetProjectionRef()\n","  n_bands = raster_dataset.RasterCount\n","  hsi_img = np.moveaxis(raster_dataset.ReadAsArray()[:251], 0, -1)\n","\n","  path = F\"/content/gdrive/My Drive/mlp_fullspectra_T0_24.pkl\"\n","  mlp_classifier =  joblib.load(open(path, 'rb'))\n","\n","  n_row, n_col, n_band = hsi_img.shape\n","  classified_img = np.empty(shape=(n_row, n_col), dtype='uint8')\n","  for i in np.arange(n_row):\n","    for j in np.arange(n_col):\n","      x_ml_tran = pd.DataFrame(hsi_img[i,j,:])\n","      x_scaled = x_ml_tran.T\n","      classified_img[i,j] = mlp_classifier.predict(scaler.transform(x_scaled))\n","\n","  # Plot the classified image\n","  import os\n","  import gdal\n","  from pylab import *\n","  plt.style.use('seaborn-ticks')\n","\n","  classified_img_mask = classified_img\n","  classified_img_mask = np.ma.masked_array(classified_img_mask, mask=(hsi_img[:, :, 180] <= mask_val))\n","\n","  # Plot classified image\n","  color_map = plt.cm.get_cmap('RdYlGn', 9)\n","  cmap = color_map.reversed()\n","  class_name = ['D-00', 'D-03', 'D-06', 'D-09', 'D-12', 'D-15', 'D-18', 'D-21', 'D-24']\n","  plt.figure(figsize=(6.5, 6))\n","  img1 = plt.imshow(classified_img_mask, interpolation='none', cmap=cmap) #plt.cm.Greens, plt.cm.YlGn, plt.cm.get_cmap('Greens', 9)\n","  plt.title(treat_day, fontsize=18)\n","  cbar = plt.colorbar(img1)\n","  cbar.set_label(label=\"Day of Treatment\", size=18)\n","  cbar.ax.tick_params(labelsize=16, rotation=0)\n","  cbar.ax.set_yticklabels(labels=class_name, va=\"center\")\n","  plt.xticks(ticks=[], labels=None)\n","  plt.yticks(ticks=[], labels=None)\n","  plt.grid(b=None)\n","  savefile = '/content/gdrive/My Drive/T0_img_fullspectra_mlp_' + treat_day \n","  plt.savefig(savefile + '.png', dpi=150)\n","  plt.show()\n","\n","  # Export classification results to GeoTIFF\n","  save_tiff_file = savefile + '.tif'\n","  prj = raster_dataset.GetProjection()\n","  geotran = raster_dataset.GetGeoTransform()\n","  save_raster(path=save_tiff_file, img = classified_img_mask, prj=prj, geotran=geotran, format='GTiff', dtype=gdal.GDT_Byte)"],"execution_count":null,"outputs":[]}]}